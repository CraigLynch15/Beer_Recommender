{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28001,
     "status": "ok",
     "timestamp": 1630975508279,
     "user": {
      "displayName": "Craig Lynch",
      "photoUrl": "",
      "userId": "01836255586579545796"
     },
     "user_tz": 360
    },
    "id": "s4GhsvnkonKh",
    "outputId": "afe698dd-a9d0-4004-fb2e-d7f8ea8583ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Using cached surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Collecting scikit-surprise\n",
      "  Using cached scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1619419 sha256=fc1b040834a8fd5516abb8571a59dc0859557a317f108bbc4c6ceab6523e1b11\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!pip install surprise\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, SVDpp\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8814,
     "status": "ok",
     "timestamp": 1630975517068,
     "user": {
      "displayName": "Craig Lynch",
      "photoUrl": "",
      "userId": "01836255586579545796"
     },
     "user_tz": 360
    },
    "id": "IdaiJL7moqe5",
    "outputId": "94c4bac3-5223-46fc-a2de-532a381fa2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(853486, 19)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "data_read = pd.read_csv('/content/drive/My Drive/LHL_Final_Project/Written_Reviews/Beer_Recommendations_EDA_V01.csv')\n",
    "data_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDNKkFPFotjH"
   },
   "outputs": [],
   "source": [
    "df = data_read.sample(frac=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohhGfgw5o2jN"
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'username': 'userID','Name':'itemID','user_overall_score':'rating'})\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 616012,
     "status": "ok",
     "timestamp": 1630981699754,
     "user": {
      "displayName": "Craig Lynch",
      "photoUrl": "",
      "userId": "01836255586579545796"
     },
     "user_tz": 360
    },
    "id": "6QqCBYE8tcCb",
    "outputId": "7e4f0167-1bab-4790-f52f-cd81b9a238ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "The shape of the matrix is: (1709, 500)\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "data_read = pd.read_csv('/content/drive/My Drive/LHL_Final_Project/Written_Reviews/Beer_Recommendations_EDA_V01.csv')\n",
    "df = data_read.copy()\n",
    "df = df.sample(frac=0.10, random_state=1)\n",
    "\n",
    "# Remove Punctuation\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "df['text'] = df['text'].apply(remove_punctuations)\n",
    "\n",
    "# Make Strings Lowercase\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "# Remove Digits\n",
    "df['text'] = df['text'].str.replace('\\d+', '')\n",
    "\n",
    "#define lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#remove stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['without_stopwords']  = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#lemmatize/tokenize/make everything lowercase/remove punctuation\n",
    "df['lemmatized_text'] = df['without_stopwords'].apply(\\\n",
    "lambda x : ' '.join([lemmatizer.lemmatize(word.lower()) \\\n",
    "    for word in word_tokenize(re.sub(r'([^\\s\\w]|_)+', ' ', str(x)))]))\n",
    "\n",
    "#remove digitsvb\n",
    "df['lemmatized_text'] = df['lemmatized_text'].str.replace('\\d+', '')\n",
    "\n",
    "#add some more stopwords\n",
    "newStopWords = ['beer', 'one', 'would', 'get', 'come', 'also', 'oz', 'could']\n",
    "stop.extend(newStopWords)\n",
    "df['lemmatized_text'] = df['lemmatized_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "df['lemmatized_text'] = df['lemmatized_text'].astype('str')\n",
    "\n",
    "\n",
    "# add some more stopwords\n",
    "newStopWords = ['lager', 'porter', 'stout', 'brewery', 'ale', 'apa', 'ipa', 'ipas', 'belgian', 'red', 'brown', 'cream', 'black', 'amber',\n",
    "               'golden', 'much', 'year', 'worth', 'english', 'german', 'american', 'stuff', 'pilsner', 'old', 'barleywine',\n",
    "               'ri', 'imperial', 'non', 'dipa', 'iipa', 'dipas', 'pils', 'pilsener', 'sam', 'irish', 'brewpub', 'st',\n",
    "               'adam', 'ml', 'tripel', 'quad', 'pa', 'ibu', 'ibus', 'series', 'bell', 'belgium', 'boston', 'city', 'coors',\n",
    "               'dead', 'dfh', 'dog', 'dogfish', 'founder', 'im', 'imo', 'lagunitas', 'left', 'nevada', 'rogue', 'samuel', 'sierra',\n",
    "               'southern', 'pint']\n",
    "stop.extend(newStopWords)\n",
    "df['lemmatized_text'] = df['lemmatized_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df['lemmatized_text'] = df['lemmatized_text'].astype('str')\n",
    "\n",
    "def nouns_adj(text):\n",
    "    #Given a string of text, tokenize the text and pull out only the nouns and adjectives.\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)]\n",
    "    return ' '.join(nouns_adj)\n",
    "\n",
    "df['adjectives/nouns'] = df['lemmatized_text'].apply(nouns_adj)\n",
    "df = df.dropna()\n",
    "\n",
    "#create new dataframe\n",
    "beer_text = df[['beer_id', 'beer_name', 'style', 'brewery_name', 'Name', 'lemmatized_text', 'adjectives/nouns']]\n",
    "\n",
    "#drop null values\n",
    "beer_text = df.dropna(axis=0, subset=['adjectives/nouns'])\n",
    "\n",
    "#group by beer, think of each beer as a \"document\"\n",
    "grouped_beer_text = beer_text.groupby(['beer_id', 'brewery_name', 'beer_name', 'Name', 'style'])['adjectives/nouns'].agg(lambda col: ''.join(col))\n",
    "\n",
    "#df\n",
    "beer_text = pd.DataFrame(grouped_beer_text)\n",
    "beer_text = beer_text.reset_index()\n",
    "\n",
    "# using lemmatized_text, create the corpus\n",
    "corpus = beer_text['adjectives/nouns']\n",
    "\n",
    "# FEATURE EXTRACTION via tfidf vectorizer\n",
    "tfidf_model = TfidfVectorizer(max_features=500,\n",
    "                             max_df=0.25,\n",
    "                             min_df=0.01)\n",
    "\n",
    "tfidf_matrix = tfidf_model.fit_transform(corpus).todense()\n",
    "print('The shape of the matrix is:', tfidf_matrix.shape)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix)\n",
    "tfidf_df.columns = sorted(tfidf_model.vocabulary_)\n",
    "\n",
    "# Calculate the cosine similarity of the matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Construct a reverse mapping of indices and beer names, and drop duplicate names, if any\n",
    "indices = pd.Series(beer_text.index, index=beer_text['Name']).drop_duplicates()\n",
    "\n",
    "print(type(indices))\n",
    "print(type(cosine_sim))\n",
    "\n",
    "indices.to_pickle('indices')\n",
    "np.save(\"cosine_sim.npy\", cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TjhGy_kxsdKn",
    "outputId": "2b17172b-e906-4de6-b945-aef3e925a74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (0.88.0)\n",
      "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.7.0)\n",
      "Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.5)\n",
      "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
      "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.1.18)\n",
      "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.18.2)\n",
      "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.4)\n",
      "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.2.0)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
      "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.0)\n",
      "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (4.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (3.7.4.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (4.0.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (6.3.1)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
      "Requirement already satisfied: argcomplete>=1.12.3 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.12.3)\n",
      "Requirement already satisfied: importlib-metadata<5 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.6.4)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.27.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.5.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.4.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.2.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.11.0)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.0.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.5.30)\n",
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.1.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n",
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1630983693550,
     "user": {
      "displayName": "Craig Lynch",
      "photoUrl": "",
      "userId": "01836255586579545796"
     },
     "user_tz": 360
    },
    "id": "rbLte8-2o5e3",
    "outputId": "f9fdb864-0f31-48b6-81cc-bc55590675bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting full.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile full.py\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from surprise import Reader, Dataset\n",
    "from surprise import SVD, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, SVDpp\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from collections import defaultdict\n",
    "from surprise import accuracy\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "\n",
    "st.set_page_config(layout=\"wide\") \n",
    "st.title('Beer Recommendations')\n",
    "\n",
    "page_names = ['Existing User', 'New User', 'Help Me Choose']\n",
    "\n",
    "page = st.radio('Navigation', page_names)\n",
    "\n",
    "st.write(page)\n",
    "\n",
    "if page == 'New User':\n",
    "\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  data_read = pd.read_csv('/content/drive/My Drive/LHL_Final_Project/Written_Reviews/Beer_Recommendations_EDA_V01.csv')\n",
    "  # User 10% of the dataset for testing\n",
    "  df_item_based = data_read.sample(frac=0.10, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "  st.header('Beer Recommendation App - Collaboration Filter')\n",
    "  st.write('This app was built to help you expand your beer horizons')\n",
    "  st.write('Data obtained from https://www.kaggle.com/ehallmar/beers-breweries-and-beer-reviews')\n",
    "\n",
    "  beer1 = 'Molson Canadian Lager'\n",
    "  beer2 = 'Guinness Extra Stout Original'\n",
    "  beer3 = 'Blue Moon Belgian White'\n",
    "  beer4 = '90 Minute IPA'\n",
    "  beer5 = 'Nut Brown Ale'\n",
    "  beer6 = 'Smoked Porter'\n",
    "  beer7 = 'Gose'\n",
    "\n",
    "\n",
    "\n",
    "  # User input for new beer\n",
    "  st.title('Rate these beer on a scale of 0-5. If you have not tried one, rate how interested you are in trying it:')\n",
    "  with st.form(key='form1'):\n",
    "    st.write('Molson Canadian Lager')\n",
    "    rating1 = st.slider(\"Rating\", min_value=0.0, max_value=5.0, step=0.25,key='1')\n",
    "    st.write('Guinness Extra Stout Original')\n",
    "    rating2 = st.slider(\"Rating\", min_value=0.0, max_value=5.0, step=0.25,key='2')\n",
    "    st.write('Blue Moon Belgian White')\n",
    "    rating3 = st.slider(\"Rating\", min_value=0.0, max_value=5.0, step=0.25,key='3')\n",
    "    st.write('90 Minute IPA')\n",
    "    rating4 = st.slider(\"Rating\", min_value=0.0, max_value=5.0, step=0.25,key='4')\n",
    "    st.write('Nut Brown Ale')\n",
    "    rating5 = st.slider(\"Rating\", min_value=0.0, max_value=5.0, step=0.25,key='5')\n",
    "    st.write('Smoked Porter')\n",
    "    rating6 = st.slider(\"Rating\", min_value=0.0, max_value=5.0, step=0.25,key='6')\n",
    "    st.write('Gose')\n",
    "    rating7 = st.slider(\"Rating\", min_value=0.0, max_value=5.0, step=0.25,key='7')\n",
    "    \n",
    "    submit = st.form_submit_button(label = 'Press Here for New Beer!')\n",
    "\n",
    "  text = ['the perfect beer for anyone who loves the summer months hanging with friends on patios and pairing anything barbecue with refreshing brews',\n",
    "          'the perfect beer for anyone who loves the bitter flavour of black coffee or a strong grapefruit',\n",
    "          'the perfect beer for anyone who loves coffee-crisp purposely burnt marshmallows and other bold rich flavours',\n",
    "          'the perfect beer for anyone who loves dried fruit Werther’s Original candy bold flavours and just a pinch of sweet flavours',\n",
    "          'the perfect beer for anyone who loves scotch campfires and smoked meats smoky brews can be enjoyed all year round',\n",
    "          'the perfect beer for anyone whos morning routine consists of chugging a glass of orange juice or anyone who never says when when the waiter is adding pepper to your meal',\n",
    "          'the perfect beers for anyone who drinks green tea in the morning instead of coffee puts cucumber in their water to give it flavour or is semi-addicted to sour penny candies']\n",
    "\n",
    "  user = [(beer1,rating1),(beer2,rating2),(beer3,rating3),(beer4,rating4),(beer5,rating5),(beer6,rating6),(beer7,rating7)]\n",
    "  user = pd.DataFrame(user, columns = ['beer_name', 'user_overall_score'])\n",
    "\n",
    "  user['brewery_name'] =  pd.np.where(user.beer_name.str.contains(\"Canadian\"), 'Molson Coors Canada',\n",
    "                          pd.np.where(user.beer_name.str.contains(\"Guinness\"), 'Guinness Ltd',\n",
    "                          pd.np.where(user.beer_name.str.contains(\"Blue Moon\"), 'Coors Brewing Company MolsonCoors',\n",
    "                          pd.np.where(user.beer_name.str.contains(\"90 Minute\"), 'Dogfish Head Craft Brewery',\n",
    "                          pd.np.where(user.beer_name.str.contains(\"Nut Brown Ale\"), 'Samuel Smith Old Brewery Tadcaster',\n",
    "                          pd.np.where(user.beer_name.str.contains(\"Smoked Porter\"), 'Alaskan Brewing Co Alaskan',\n",
    "                          pd.np.where(user.beer_name.str.contains(\"Flemish\"), 'Brouwerij Van Steenberge NV', 'Westbrook Brewing Co')))))))\n",
    "\n",
    "  user['beer_id'] = pd.np.where(user.beer_name.str.contains(\"Canadian\"), '1312.0',\n",
    "                    pd.np.where(user.beer_name.str.contains(\"Guinness\"), '650.0',\n",
    "                    pd.np.where(user.beer_name.str.contains(\"Blue Moon\"), '1212.0',\n",
    "                    pd.np.where(user.beer_name.str.contains(\"90 Minute\"), '2093.0',\n",
    "                    pd.np.where(user.beer_name.str.contains(\"Nut Brown Ale\"), '576.0',\n",
    "                    pd.np.where(user.beer_name.str.contains(\"Smoked Porter\"), '90.0',\n",
    "                    pd.np.where(user.beer_name.str.contains(\"Flemish\"), '10482.0', '133043.0')))))))\n",
    "\n",
    "  user['text'] = pd.np.where(user.beer_name.str.contains(\"Lager\"), text[0],\n",
    "                pd.np.where(user.beer_name.str.contains(\"IPA\"), text[1],\n",
    "                pd.np.where(user.beer_name.str.contains(\"Stout\"), text[2],\n",
    "                pd.np.where(user.beer_name.str.contains(\"Brown Ale\"), text[3],\n",
    "                pd.np.where(user.beer_name.str.contains(\"Smoke\"), text[4],\n",
    "                pd.np.where(user.beer_name.str.contains(\"White\"), text[5], text[6]))))))\n",
    "\n",
    "  new_ratings_df = df_item_based.append(user,ignore_index=True)\n",
    "  new_ratings_df = new_ratings_df.fillna(0)\n",
    "  new_ratings_df = new_ratings_df[['username','Name','user_overall_score']]\n",
    "  new_ratings_df['user_overall_score'] = new_ratings_df['user_overall_score'].astype(float, errors = 'raise')\n",
    "  ratings = new_ratings_df.pivot_table(index='username', columns='Name', values='user_overall_score')\n",
    "  ratings.fillna(0,inplace=True)\n",
    "\n",
    "  # Removing sparsity \n",
    "  csr_ratings = csr_matrix(ratings.values)\n",
    "  # Standardize the mean of each user to 0, and correct for harsh/lenient users\n",
    "  def standardize(row):\n",
    "    new_row = (row - row.mean()) / (row.max() - row.min())\n",
    "    return new_row\n",
    "\n",
    "  ratings_std = ratings.apply(standardize)\n",
    "\n",
    "  # For item-to-item Similarity\n",
    "  item_similarity = cosine_similarity(ratings_std.T)\n",
    "  item_similarity_df = pd.DataFrame(item_similarity,index=ratings_std.columns, columns=ratings_std.columns)\n",
    "\n",
    "\n",
    "\n",
    "  def get_similar_beer(beer_name,user_rating):\n",
    "    similar_score = item_similarity_df[beer_name]*(user_rating - 2.5)\n",
    "    similar_score = similar_score.sort_values(ascending = False)\n",
    "    return similar_score\n",
    "\n",
    "  # Using user input beer\n",
    "  user['Name'] = user['brewery_name']+' '+user['beer_name']\n",
    "  new_user = user[['Name', 'user_overall_score']]\n",
    "  new_user_list = new_user.to_records(index=False).tolist()\n",
    "\n",
    "  similar_beer = pd.DataFrame()\n",
    "\n",
    "  for beer, rating in new_user_list:\n",
    "    similar_beer = similar_beer.append(get_similar_beer(beer,rating))\n",
    "    x = similar_beer.sum().sort_values(ascending= False)\n",
    "    x = pd.DataFrame(x).reset_index()\n",
    "    x = x.rename(columns={'index': 'Name',0:'Score'})\n",
    "    y = pd.DataFrame(new_user_list)\n",
    "    y = y.rename(columns={0: 'Name',1:'Score'})\n",
    "    x = x[~x['Name'].isin(y['Name'])]\n",
    "    \n",
    "  # top_choices = x.head(10)\n",
    "  # bottom_choices = x.tail(1)\n",
    "  st.write('Top Beer Choices')\n",
    "  st.write(x['Name'].head(10))\n",
    "  st.write('Or Maybe Something Completely Different')\n",
    "  st.write(x['Name'].tail(1))\n",
    "\n",
    "elif page == 'Existing User':\n",
    "\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  data_read = pd.read_csv('/content/drive/My Drive/LHL_Final_Project/Written_Reviews/Beer_Recommendations_EDA_V01.csv')\n",
    "  df = data_read.sample(frac=0.10, random_state=42)\n",
    "  df = df.rename(columns={'username': 'userID','Name':'itemID','user_overall_score':'rating'})\n",
    "  df_copy = df.copy()\n",
    "  df_copy['Name'] = df_copy['brewery_name']+' '+df_copy['beer_name']\n",
    "  df_copy = df_copy[['userID', 'Name', 'itemID', 'style', 'rating']]\n",
    "\n",
    "  reader = Reader(rating_scale=(0, 5))\n",
    "  df = Dataset.load_from_df(df[['userID', \t'itemID', \t'rating' \t]], reader=reader)\n",
    "  # Creating a train/test set within Surprise\n",
    "  raw_ratings = df.raw_ratings\n",
    "  threshold = int(.7 * len(raw_ratings))                                     \n",
    "  trainset_raw_ratings = raw_ratings[:threshold]                             \n",
    "  test_raw_ratings = raw_ratings[threshold:]  \n",
    "  df.raw_ratings = trainset_raw_ratings\n",
    "\n",
    "  algo_SVD = SVD(n_factors = 4)\n",
    "  trainset = df.build_full_trainset()\n",
    "  algo_SVD.fit(trainset)\n",
    "  print('algorithm: SVD with GridSearchCV')\n",
    "  # Trainset\n",
    "  predictions = algo_SVD.test(trainset.build_testset())\n",
    "  print('Biased accuracy on trainset,', end='   ')\n",
    "  accuracy.rmse(predictions)\n",
    "  # Testset\n",
    "  testset = df.construct_testset(test_raw_ratings)\n",
    "\n",
    "  predictions = algo_SVD.test(testset)\n",
    "  print('Unbiased accuracy on testset,', end=' ')\n",
    "  accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "  def get_top_n(predictions, userID, df_copy, n = 10):\n",
    "      '''Return the top N (default) itemID for a user,.i.e. userID and history for comparison\n",
    "      Args:\n",
    "      Returns: \n",
    "    \n",
    "      '''\n",
    "      #Part I.: Surprise docomuntation\n",
    "      \n",
    "      #1. First map the predictions to each user.\n",
    "      top_n = defaultdict(list)\n",
    "      for uid, iid, true_r, est, _ in predictions:\n",
    "          top_n[uid].append((iid, est))\n",
    "\n",
    "      #2. Then sort the predictions for each user and retrieve the k highest ones.\n",
    "      for uid, user_ratings in top_n.items():\n",
    "          user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "          top_n[uid] = user_ratings[: n ]\n",
    "      \n",
    "      #Part II.: inspired by: https://beckernick.github.io/matrix-factorization-recommender/\n",
    "      \n",
    "      #3. Tells how many beer the user has already rated\n",
    "      user_data = df_copy[df_copy.userID == (userID)]\n",
    "      print('User {0} has already rated {1} beer.'.format(userID, user_data.shape[0]))\n",
    "\n",
    "      \n",
    "      #4. Data Frame with predictions. \n",
    "      preds_df = pd.DataFrame([(id, pair[0],pair[1]) for id, row in top_n.items() for pair in row],\n",
    "                          columns=[\"userID\" ,\"itemID\",\"rat_pred\"])\n",
    "      \n",
    "      \n",
    "      #5. Return pred_usr, i.e. top N recommended beer. \n",
    "      pred_usr = pd.merge(preds_df[preds_df[\"userID\"] == (userID)],df_copy, on = 'itemID')\n",
    "      pred_usr = pred_usr.rename(columns={'userID_x': 'userID'})\n",
    "      pred_usr = pred_usr[['userID', 'itemID', 'style', 'rat_pred']]\n",
    "              \n",
    "      #6. Return hist_usr, i.e. top N historically rated beer.\n",
    "      hist_usr = df_copy[['userID','itemID','style','rating']]\n",
    "      hist_usr = hist_usr[hist_usr['userID'] == userID]\n",
    "      \n",
    "      \n",
    "      return hist_usr, pred_usr\n",
    "\n",
    "\n",
    "  st.header('Recommendations for Existing Users')\n",
    "\n",
    "  # Sample of usernames for testing\n",
    "  st.write('Sample Usernames')\n",
    "  st.dataframe(df_copy['userID'].sample(20))\n",
    "\n",
    "  with st.form(key='form1'):  \n",
    "    username = st.text_input('Select Username')\n",
    "    st.form_submit_button(label = 'Press Here for New Beer!')\n",
    "    hist_SVD, pred_SVD = get_top_n(predictions, df_copy = df_copy, userID = username)\n",
    "\n",
    "\n",
    "  st.write('Displaying Recommendations for User: ', username)\n",
    "\n",
    "  pred_SVD = pred_SVD.drop_duplicates('itemID')\n",
    "  hist_SVD = hist_SVD.drop_duplicates('itemID')\n",
    "  st.write('Recommendations')\n",
    "  st.dataframe(pred_SVD)\n",
    "  st.write('Previous Ratings')\n",
    "  st.dataframe(hist_SVD)\n",
    "\n",
    "else:\n",
    "\n",
    "  import pickle\n",
    "  indices = pd.read_pickle('indices')\n",
    "  cosine_sim = np.load(\"cosine_sim.npy\")\n",
    "  beer_text = pd.read_csv('/content/drive/My Drive/LHL_Final_Project/Written_Reviews/beer_text.csv')\n",
    "\n",
    "\n",
    "  st.title('Beer Recommendation App - Content Recommendation')\n",
    "  st.write('This app was built to help you expand your beer horizons')\n",
    "  st.write('Data obtained from https://www.kaggle.com/ehallmar/beers-breweries-and-beer-reviews')\n",
    "\n",
    "\n",
    "  def content_recommender(title, cosine_sim=cosine_sim, df=beer_text, indices=indices):\n",
    "      # Obtain the index of the beer that matches the name\n",
    "      idx = indices[title]\n",
    "      sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "      sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "      sim_scores = sim_scores[1:11]\n",
    "      beer_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "      \n",
    "      return beer_text[['style', 'brewery_name', 'beer_name']].iloc[beer_indices]\n",
    "\n",
    "  st.write('What are you in the mood for?')\n",
    "\n",
    "  want = st.selectbox('Select', ['I want a beer for summer, hanging with friends on patios, and barbecueing.',\n",
    "          'I love the bitter flavour of black coffee or a strong grapefruit.',\n",
    "          'I love coffee-crisp, purposely burnt marshmallows, and other bold rich flavours.',\n",
    "          'I love dried fruit, Werther’s Originals, bold flavours, and just a pinch of sweet.',\n",
    "          'I love scotch, campfires, and smoked meats.',\n",
    "          \"I love a glass of orange juice and I never says 'when' when the waiter is adding pepper to my meal.\",\n",
    "          'I drink green tea instead of coffee, love cucumber in my water, and am semi-addicted to sour candies'])\n",
    "  if 'barbecue' in want:\n",
    "    test_beer = 'Molson Coors Canada Molson Canadian Lager'\n",
    "  elif 'marshmallows' in want:\n",
    "    test_beer = 'Guinness Ltd Guinness Extra Stout Original'\n",
    "  elif 'chugging' in want:\n",
    "    test_beer = 'Coors Brewing Company MolsonCoors Blue Moon Belgian White'\n",
    "  elif 'grapefruit' in want:\n",
    "    test_beer = 'Dogfish Head Craft Brewery 90 Minute IPA'\n",
    "  elif 'Original' in want:\n",
    "    test_beer = 'Samuel Smith Old Brewery Tadcaster Nut Brown Ale'\n",
    "  elif 'smoked' in want:\n",
    "    test_beer = 'Alaskan Brewing Co Alaskan Smoked Porter'\n",
    "  elif 'cucumber' in want:\n",
    "    test_beer = 'Westbrook Brewing Co Gose'\n",
    "  else:\n",
    "    test_beer = \"I'm not a beer person\"\n",
    "\n",
    "\n",
    "  st.write(content_recommender(test_beer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1630981737822,
     "user": {
      "displayName": "Craig Lynch",
      "photoUrl": "",
      "userId": "01836255586579545796"
     },
     "user_tz": 360
    },
    "id": "ziEkD0tXpmim",
    "outputId": "0c8461bd-a9c7-4097-cd40-71f758ee48bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_sim.npy\tdrive  full.py\tindices  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert ngrok authtoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1630984664367,
     "user": {
      "displayName": "Craig Lynch",
      "photoUrl": "",
      "userId": "01836255586579545796"
     },
     "user_tz": 360
    },
    "id": "qMgzLsgapmtO",
    "outputId": "04d5c1b7-ed53-40dc-9936-0672fa07512d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<NgrokTunnel: \"http://e7e6-35-186-183-225.ngrok.io\" -> \"http://localhost:80\">"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "!ngrok authtoken XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "from pyngrok import ngrok\n",
    "!streamlit run --server.port 80 full.py&>/dev/null&\n",
    "publ_url = ngrok.connect(port='80')\n",
    "publ_url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT5WoN60-TFu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kb-yD5S4-TII"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBL6L2zn-TKx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoX3pjCt-TNP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SecESgCP-TQV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1630983205320,
     "user": {
      "displayName": "Craig Lynch",
      "photoUrl": "",
      "userId": "01836255586579545796"
     },
     "user_tz": 360
    },
    "id": "5E2Hl8Kwpmvu"
   },
   "outputs": [],
   "source": [
    "ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "cyimU4dts1Th"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPCb3MaWoDkQ9kdj/bKzoAt",
   "collapsed_sections": [],
   "name": "Deploy_Beer_Recommendations_Streamlet_Full.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
